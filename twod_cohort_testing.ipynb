{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2479ccb0-0cf2-4946-b1d4-758524c14a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import tempfile\n",
    "import pickle\n",
    "import math\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b436f8e9-c023-4530-bd85-6515d2f400f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def length_to_distance(length: float) -> float:\n",
    "    return (2 - 2*math.cos(length))**(1/2)\n",
    "\n",
    "def distance_to_length(distance: float) -> float:\n",
    "    return math.acos((2-distance**2)/2)\n",
    "\n",
    "def score_to_distance(score: float) -> float:\n",
    "    return similarity_to_distance(score_to_similarity(score))\n",
    "\n",
    "def distance_to_similarity(distance: float) -> float:\n",
    "    return (2 - distance ** 2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f592e854-5b35-4fd0-a00b-144b409a7d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiles: \n",
      "{'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16'], 'profile_embedding': [[1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1], [-0.5, 0.8660254037844386], [-0.7071067811865475, 0.7071067811865475], [-0.8660254037844386, 0.5], [-1, 0], [-0.8660254037844386, -0.5], [-0.7071067811865475, -0.7071067811865475], [-0.5, -0.8660254037844386], [0, -1], [0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5]]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the 2D ids and embeddings\n",
    "# create profiles dictionary\n",
    "profile_ids = list([f\"P{i+1}\" for i in range(16)])\n",
    "profile_embeddings = list([[1, 0], [3**(1/2)/2, 1/2], [1/2**(1/2), 1/2**(1/2)], [1/2, 3**(1/2)/2], \n",
    "                      [0, 1], [-1/2, 3**(1/2)/2], [-1/2**(1/2), 1/2**(1/2)], [-3**(1/2)/2, 1/2],\n",
    "                      [-1, 0], [-3**(1/2)/2, -1/2], [-1/2**(1/2), -1/2**(1/2)], [-1/2, -3**(1/2)/2], \n",
    "                      [0, -1], [1/2, -3**(1/2)/2], [1/2**(1/2), -1/2**(1/2)], [3**(1/2)/2, -1/2]\n",
    "                     ])\n",
    "\n",
    "profiles = {\"profile_id\": profile_ids, \"profile_embedding\": profile_embeddings}\n",
    "print(f\"profiles: \")\n",
    "print(f\"{profiles}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4be153c9-8292-4598-b715-770fe36295d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohorts: \n",
      "{'cohort_id': ['C1', 'C2', 'C3'], 'cohort_embedding': [[0.7071067811865475, 0.7071067811865475], [-0.7071067811865475, 0.7071067811865475], [-0.7071067811865475, -0.7071067811865475]]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create cohorts for QII, QIII, QIV\n",
    "cohort_ids = [f\"C{i+1}\" for i in range(3)]\n",
    "cohort_embeddings = [[1/2**(1/2), 1/2**(1/2)], [-1/2**(1/2), 1/2**(1/2)], [-1/2**(1/2), -1/2**(1/2)]]\n",
    "cohorts = {\"cohort_id\": cohort_ids, \"cohort_embedding\": cohort_embeddings}\n",
    "print(f\"cohorts: \")\n",
    "print(f\"{cohorts}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0645a275-f2d5-4c2b-a4c4-b9e5805c4cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  \n",
      "{'query_id': ['Q1', 'Q2', 'Q3'], 'query_embedding': [[1, 0], [-0.8660254037844386, 0.5], [0.5, -0.8660254037844386]]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create queries: for this example query embeddings = [cos(theta), sin(theta)] for theta = pi/6, 5pi/6, pi/3\n",
    "query_ids = [f\"Q{i+1}\" for i in range(3)]\n",
    "query_embeddings = [[1, 0], [-3**(1/2)/2, 1/2], [1/2, -3**(1/2)/2]]\n",
    "queries = {\"query_id\": query_ids, \"query_embedding\": query_embeddings}\n",
    "print(f\"queries:  \")\n",
    "print(f\"{queries}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c81c6e6-3762-45e3-bf3e-62f10525e3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the cohort radius\n",
    "# for theta = pi/2 -> cohort_radius = sqrt(2), for theta = pi/4 -> cohort_radius = sqrt(2 - sqrt(2)), for theta = pi/3 -> cohort_radius = 1\n",
    "cohort_radius = 1\n",
    "query_radius = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc9aff56-18d3-4428-a49a-60d7e57584c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cohort assignment algorithm\n",
    "# tag profiles with cohorts in range, tag cohorts with profiles in range\n",
    "profile_cohort_ids = []\n",
    "cohort_profile_ids = {cohort_id: [] for cohort_id in cohort_ids}  # Dictionary to track profiles for each cohort\n",
    "\n",
    "def multiple_cohort_assignment(cohorts, profiles, cohort_radius):\n",
    "    cohort_ids = np.array(cohorts[\"cohort_id\"]) \n",
    "    cohort_embeddings = np.array(cohorts[\"cohort_embedding\"])\n",
    "    profile_ids = np.array(profiles[\"profile_id\"]) \n",
    "    profile_embeddings = np.array(profiles[\"profile_embedding\"])\n",
    "    print(f\"Assigning {len(profile_ids)} profiles to {len(cohort_ids)} cohorts...\")\n",
    "\n",
    "    knn = NearestNeighbors(algorithm='brute', metric=\"euclidean\", n_jobs=-1)\n",
    "    knn.fit(cohort_embeddings)\n",
    "    cohort_distances, cohort_indices = knn.kneighbors(profile_embeddings, n_neighbors=3, return_distance=True)\n",
    "    \n",
    "    # Properly initialize cohort_profile_ids dictionary\n",
    "    cohort_profile_ids = {cohort_id: [] for cohort_id in cohort_ids}\n",
    "    profile_cohort_ids = []\n",
    "    \n",
    "    for profile_idx, (distances, indices) in enumerate(zip(cohort_distances, cohort_indices)):\n",
    "        assigned_cohort_ids = []\n",
    "        for distance, cohort_idx in zip(distances, indices):\n",
    "            if distance <= cohort_radius:\n",
    "                cohort_id = cohort_ids[cohort_idx]\n",
    "                assigned_cohort_ids.append(cohort_id)\n",
    "                cohort_profile_ids[cohort_id].append(profile_ids[profile_idx])  # Track profiles in respective cohorts\n",
    "        profile_cohort_ids.append(assigned_cohort_ids)\n",
    "\n",
    "    tagged_profiles = [\n",
    "        {\"profile_id\": pid, \"profile_embedding\": pembed, \"cohort_ids\": cid}\n",
    "        for pid, pembed, cid in zip(profile_ids, profile_embeddings, profile_cohort_ids)\n",
    "    ]\n",
    "\n",
    "    tagged_cohorts = [\n",
    "        {\"cohort_id\": cid, \"cohort_embedding\": cembed, \"profile_ids\": cohort_profile_ids[cid]}\n",
    "        for cid, cembed in zip(cohort_ids, cohort_embeddings)\n",
    "    ]\n",
    "\n",
    "    return tagged_profiles, tagged_cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "133f3f7c-91f4-4442-ae2f-e97dc94591e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning 16 profiles to 3 cohorts...\n",
      "tagged_profiles: [{'profile_id': 'P1', 'profile_embedding': array([1., 0.]), 'cohort_ids': ['C1']}, {'profile_id': 'P2', 'profile_embedding': array([0.8660254, 0.5      ]), 'cohort_ids': ['C1']}, {'profile_id': 'P3', 'profile_embedding': array([0.70710678, 0.70710678]), 'cohort_ids': ['C1']}, {'profile_id': 'P4', 'profile_embedding': array([0.5      , 0.8660254]), 'cohort_ids': ['C1']}, {'profile_id': 'P5', 'profile_embedding': array([0., 1.]), 'cohort_ids': ['C1', 'C2']}, {'profile_id': 'P6', 'profile_embedding': array([-0.5      ,  0.8660254]), 'cohort_ids': ['C2']}, {'profile_id': 'P7', 'profile_embedding': array([-0.70710678,  0.70710678]), 'cohort_ids': ['C2']}, {'profile_id': 'P8', 'profile_embedding': array([-0.8660254,  0.5      ]), 'cohort_ids': ['C2']}, {'profile_id': 'P9', 'profile_embedding': array([-1.,  0.]), 'cohort_ids': ['C3', 'C2']}, {'profile_id': 'P10', 'profile_embedding': array([-0.8660254, -0.5      ]), 'cohort_ids': ['C3']}, {'profile_id': 'P11', 'profile_embedding': array([-0.70710678, -0.70710678]), 'cohort_ids': ['C3']}, {'profile_id': 'P12', 'profile_embedding': array([-0.5      , -0.8660254]), 'cohort_ids': ['C3']}, {'profile_id': 'P13', 'profile_embedding': array([ 0., -1.]), 'cohort_ids': ['C3']}, {'profile_id': 'P14', 'profile_embedding': array([ 0.5      , -0.8660254]), 'cohort_ids': []}, {'profile_id': 'P15', 'profile_embedding': array([ 0.70710678, -0.70710678]), 'cohort_ids': []}, {'profile_id': 'P16', 'profile_embedding': array([ 0.8660254, -0.5      ]), 'cohort_ids': []}]\n",
      "\n",
      "tagged_cohorts: [{'cohort_id': 'C1', 'cohort_embedding': array([0.70710678, 0.70710678]), 'profile_ids': ['P1', 'P2', 'P3', 'P4', 'P5']}, {'cohort_id': 'C2', 'cohort_embedding': array([-0.70710678,  0.70710678]), 'profile_ids': ['P5', 'P6', 'P7', 'P8', 'P9']}, {'cohort_id': 'C3', 'cohort_embedding': array([-0.70710678, -0.70710678]), 'profile_ids': ['P9', 'P10', 'P11', 'P12', 'P13']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_profiles, tagged_cohorts = multiple_cohort_assignment(cohorts, profiles, cohort_radius)\n",
    "\n",
    "print(f\"tagged_profiles: {tagged_profiles}\")\n",
    "print()\n",
    "print(f\"tagged_cohorts: {tagged_cohorts}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64eff812-6fc0-47c3-a886-605067202bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cohort querying algorithms\n",
    "# brute force for precision and recall measures\n",
    "def brute_force_search(queries, tagged_profiles, min_cosine_similarity):\n",
    "    query_embeddings = np.array(queries[\"query_embedding\"])\n",
    "    profile_embeddings = np.stack([profile[\"profile_embedding\"] for profile in tagged_profiles])    \n",
    "    cosine_similarities = cosine_similarity(query_embeddings, profile_embeddings)    \n",
    "    return [len(profile_embeddings)] * len(query_embeddings), (cosine_similarities >= min_cosine_similarity).astype(int)\n",
    "\n",
    "\n",
    "def cohort_search(queries, tagged_cohorts, query_radius, cohort_radius):\n",
    "    cohort_ids = [cohort[\"cohort_id\"] for cohort in tagged_cohorts]\n",
    "    cohort_embeddings = np.stack([cohort[\"cohort_embedding\"] for cohort in tagged_cohorts]) if tagged_cohorts else np.array([])\n",
    "    query_ids = queries[\"query_id\"]\n",
    "    query_embeddings = np.array(queries[\"query_embedding\"])\n",
    "    \n",
    "    print(f\"Querying cohorts...\")\n",
    "    if cohort_embeddings.size > 0:\n",
    "        cohort_knn = NearestNeighbors(algorithm='brute', metric=\"euclidean\", n_jobs=-1)\n",
    "        cohort_knn.fit(cohort_embeddings)\n",
    "        all_cohort_indices = cohort_knn.radius_neighbors(\n",
    "            query_embeddings,\n",
    "            radius=length_to_distance(distance_to_length(query_radius) + distance_to_length(cohort_radius)),\n",
    "            return_distance=False\n",
    "        )\n",
    "    else:\n",
    "        all_cohort_indices = [[] for _ in range(len(query_embeddings))]\n",
    "    \n",
    "    print(f\"There are {[len(cohort_indices) for cohort_indices in all_cohort_indices]} cohorts matched to each query, respectively.\")\n",
    "    \n",
    "    return cohort_ids, all_cohort_indices\n",
    "\n",
    "\n",
    "def collect_profiles_to_query(tagged_profiles, cohort_ids, all_cohort_indices, query_count):\n",
    "    profiles_to_query = {query_idx: {\"profile_id\": [], \"profile_embedding\": []} for query_idx in range(query_count)}\n",
    "\n",
    "    for query_idx in range(query_count):\n",
    "        cohort_matched_profiles = OrderedDict()  # Preserves insertion order\n",
    "        \n",
    "        for cohort_idx in all_cohort_indices[query_idx]:\n",
    "            cohort_id = cohort_ids[cohort_idx]\n",
    "            inner_profiles = [(profile[\"profile_id\"], profile[\"profile_embedding\"]) \n",
    "                              for profile in tagged_profiles if cohort_id in profile[\"cohort_ids\"]]\n",
    "            \n",
    "            for profile_id, embedding in inner_profiles:\n",
    "                if profile_id not in cohort_matched_profiles:\n",
    "                    cohort_matched_profiles[profile_id] = embedding\n",
    "        \n",
    "        # Extend the lists while maintaining order\n",
    "        profiles_to_query[query_idx][\"profile_id\"].extend(cohort_matched_profiles.keys())\n",
    "        profiles_to_query[query_idx][\"profile_embedding\"].extend(cohort_matched_profiles.values())\n",
    "\n",
    "    # Retrieve uncohorted profiles\n",
    "    uncohorted_profiles = [(profile[\"profile_id\"], profile[\"profile_embedding\"]) \n",
    "                           for profile in tagged_profiles if not profile[\"cohort_ids\"]]\n",
    "\n",
    "    for query_idx in range(query_count):\n",
    "        for profile_id, embedding in uncohorted_profiles:\n",
    "            profiles_to_query[query_idx][\"profile_id\"].append(profile_id)\n",
    "            profiles_to_query[query_idx][\"profile_embedding\"].append(embedding)\n",
    "\n",
    "    inner_profile_calculation_counts = [len(profiles_to_query[q_idx]['profile_id']) for q_idx in range(query_count)]\n",
    "\n",
    "    print(f\"Profiles collected per query: {inner_profile_calculation_counts}\")\n",
    "    print(f\"profiles_to_query: \")\n",
    "    print(f\"{profiles_to_query}\")\n",
    "\n",
    "    return profiles_to_query\n",
    "\n",
    "\n",
    "def profile_search(queries, tagged_profiles, cohort_ids, all_cohort_indices, query_radius):\n",
    "    query_ids = queries[\"query_id\"]\n",
    "    query_embeddings = np.array(queries[\"query_embedding\"])\n",
    "    \n",
    "    print(f\"Querying profiles...\")\n",
    "\n",
    "    # Collect profiles to query\n",
    "    profiles_to_query = collect_profiles_to_query(tagged_profiles, cohort_ids, all_cohort_indices, len(query_ids))\n",
    "    \n",
    "    # Count of profiles in each cohort per query\n",
    "    cohort_calculation_counts = [len(cohort_ids) + len(profiles_to_query[q_idx][\"profile_id\"]) for q_idx in range(len(query_ids))]\n",
    "    print(f\"Cohort calculation counts per query: {cohort_calculation_counts}\")\n",
    "    \n",
    "    # Initialize the list to hold profile ids in range for each query\n",
    "    in_range_profile_ids = [[] for _ in range(len(query_ids))]\n",
    "    \n",
    "    # Query processing: find profiles in range for each query\n",
    "    for query_idx in range(len(query_ids)):\n",
    "        profiles = profiles_to_query[query_idx]\n",
    "        print(f\"profiles_to_query for query_idx {query_idx}: \")\n",
    "        print(f\"{profiles}\")\n",
    "        embeddings = np.array(profiles[\"profile_embedding\"]) if profiles[\"profile_embedding\"] else np.array([])\n",
    "\n",
    "        if embeddings.size > 0:\n",
    "            # Perform the nearest neighbor search\n",
    "            profile_knn = NearestNeighbors(algorithm=\"brute\", metric=\"euclidean\", n_jobs=-1)\n",
    "            profile_knn.fit(embeddings)\n",
    "            all_inner_profile_indices = profile_knn.radius_neighbors([query_embeddings[query_idx]], radius=query_radius, return_distance=False)[0]\n",
    "            print()\n",
    "            print(f\"all_inner_profile_indices for query_idx {query_idx}: \")\n",
    "            print(all_inner_profile_indices)\n",
    "            print()\n",
    "            in_range_profile_ids[query_idx] = [profiles[\"profile_id\"][i] for i in all_inner_profile_indices]\n",
    "    \n",
    "    print(f\"in_range_profile_ids: \")\n",
    "    print(in_range_profile_ids)\n",
    "    print()\n",
    "    # Map profile_id to index for fast lookup\n",
    "    profile_id_to_index = {profile[\"profile_id\"]: idx for idx, profile in enumerate(tagged_profiles)}\n",
    "    \n",
    "    # Initialize the result array (query x profiles)\n",
    "    cohort_query_results = np.zeros((len(query_ids), len(tagged_profiles)), dtype=int)\n",
    "\n",
    "    # For each query, create a set of in-range profile IDs for fast lookup\n",
    "    for query_idx in range(len(query_ids)):\n",
    "        matched_profile_ids = in_range_profile_ids[query_idx]\n",
    "        for profile_idx, profile in enumerate(tagged_profiles):\n",
    "            # Check if the profile_id is in the matched_profile_ids\n",
    "            if profile[\"profile_id\"] in matched_profile_ids:\n",
    "                cohort_query_results[query_idx, profile_idx] = 1\n",
    "            else:\n",
    "                cohort_query_results[query_idx, profile_idx] = 0\n",
    "\n",
    "    # Print out statistics\n",
    "    print(f\"Total Queries Processed: {len(in_range_profile_ids)}, Expected: {len(query_ids)}\")\n",
    "    print(f\"Profiles matched per query: {[len(in_range_profile_ids[q_idx]) for q_idx in range(len(query_ids))]}\")\n",
    "    print(f\"cohort_query_results shape: {cohort_query_results.shape}\")\n",
    "    \n",
    "    return cohort_calculation_counts, cohort_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cd5f496-190e-445b-9b82-828835ee6554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute_force_calculation_counts: [16, 16, 16]\n",
      "\n",
      "brute_force_query_results: \n",
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "brute_force_calculation_counts, brute_force_query_results = brute_force_search(queries, tagged_profiles, distance_to_similarity(query_radius))\n",
    "\n",
    "print(f\"brute_force_calculation_counts: {brute_force_calculation_counts}\")\n",
    "print()\n",
    "print(f\"brute_force_query_results: \")\n",
    "print(f\"{brute_force_query_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "888c5e8a-2c7d-436f-8ac5-bb3531a70b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying cohorts...\n",
      "There are [1, 3, 2] cohorts matched to each query, respectively.\n",
      "cohort_ids: ['C1', 'C2', 'C3']\n",
      "\n",
      "all_cohort_indices: [array([0]) array([0, 1, 2]) array([0, 2])]\n"
     ]
    }
   ],
   "source": [
    "cohort_ids, all_cohort_indices = cohort_search(queries, tagged_cohorts, query_radius, cohort_radius)\n",
    "\n",
    "print(f\"cohort_ids: {cohort_ids}\")\n",
    "print()\n",
    "print(f\"all_cohort_indices: {all_cohort_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65487067-300c-468b-9490-0293e65761c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying profiles...\n",
      "Profiles collected per query: [8, 16, 13]\n",
      "profiles_to_query: \n",
      "{0: {'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}, 1: {'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([-0.5      ,  0.8660254]), array([-0.70710678,  0.70710678]), array([-0.8660254,  0.5      ]), array([-1.,  0.]), array([-0.8660254, -0.5      ]), array([-0.70710678, -0.70710678]), array([-0.5      , -0.8660254]), array([ 0., -1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}, 2: {'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([-1.,  0.]), array([-0.8660254, -0.5      ]), array([-0.70710678, -0.70710678]), array([-0.5      , -0.8660254]), array([ 0., -1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}}\n",
      "Cohort calculation counts per query: [11, 19, 16]\n",
      "profiles_to_query for query_idx 0: \n",
      "{'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}\n",
      "\n",
      "all_inner_profile_indices for query_idx 0: \n",
      "[0 1 2 3 5 6 7]\n",
      "\n",
      "profiles_to_query for query_idx 1: \n",
      "{'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([-0.5      ,  0.8660254]), array([-0.70710678,  0.70710678]), array([-0.8660254,  0.5      ]), array([-1.,  0.]), array([-0.8660254, -0.5      ]), array([-0.70710678, -0.70710678]), array([-0.5      , -0.8660254]), array([ 0., -1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}\n",
      "\n",
      "all_inner_profile_indices for query_idx 1: \n",
      "[4 5 6 7 8 9]\n",
      "\n",
      "profiles_to_query for query_idx 2: \n",
      "{'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16'], 'profile_embedding': [array([1., 0.]), array([0.8660254, 0.5      ]), array([0.70710678, 0.70710678]), array([0.5      , 0.8660254]), array([0., 1.]), array([-1.,  0.]), array([-0.8660254, -0.5      ]), array([-0.70710678, -0.70710678]), array([-0.5      , -0.8660254]), array([ 0., -1.]), array([ 0.5      , -0.8660254]), array([ 0.70710678, -0.70710678]), array([ 0.8660254, -0.5      ])]}\n",
      "\n",
      "all_inner_profile_indices for query_idx 2: \n",
      "[ 0  8  9 10 11 12]\n",
      "\n",
      "in_range_profile_ids: \n",
      "[['P1', 'P2', 'P3', 'P4', 'P14', 'P15', 'P16'], ['P5', 'P6', 'P7', 'P8', 'P9', 'P10'], ['P1', 'P12', 'P13', 'P14', 'P15', 'P16']]\n",
      "\n",
      "Total Queries Processed: 3, Expected: 3\n",
      "Profiles matched per query: [7, 6, 6]\n",
      "cohort_query_results shape: (3, 16)\n",
      "cohort_calculation_counts: [11, 19, 16]\n",
      "\n",
      "cohort_query_results: \n",
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cohort_calculation_counts, cohort_query_results = profile_search(queries, tagged_profiles, cohort_ids, all_cohort_indices, query_radius)\n",
    "\n",
    "print(f\"cohort_calculation_counts: {cohort_calculation_counts}\")\n",
    "print()\n",
    "print(f\"cohort_query_results: \")\n",
    "print(f\"{cohort_query_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac30dc94-bde7-481a-a35e-2c1205a59399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_results(y_trues: list[list[int]], y_preds: list[list[int]]):\n",
    "    y_trues_counts = [len(y_trues[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    y_preds_counts = [len(y_preds[query_idx]) for query_idx in range(len(y_preds))]\n",
    "    print(f\"Counts of y_trues by query: {y_trues_counts}.\")\n",
    "    print(f\"Counts of y_preds by query: {y_preds_counts}.\")\n",
    "    precisions = [precision_score(y_trues[query_idx], y_preds[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    recalls = [recall_score(y_trues[query_idx], y_preds[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bac8c90-9e65-4b37-abd7-af6370395fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of y_trues by query: [16, 16, 16].\n",
      "Counts of y_preds by query: [16, 16, 16].\n",
      "precisions: [1.0, 1.0, 1.0]\n",
      "recalls: [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls = score_results(brute_force_query_results, cohort_query_results)\n",
    "\n",
    "print(f\"precisions: {precisions}\")\n",
    "print(f\"recalls: {recalls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb7142a-6d6f-4367-a917-65748dcb7b07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query_id': 'Q1', 'calculation_count': 11, 'precision': 1.0, 'recall': 1.0}, {'query_id': 'Q2', 'calculation_count': 19, 'precision': 0.8333333333333334, 'recall': 1.0}, {'query_id': 'Q3', 'calculation_count': 16, 'precision': 0.8333333333333334, 'recall': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "final_results = [{\"query_id\": query_ids[query_idx],\n",
    "                      \"calculation_count\": cohort_calculation_counts[query_idx],\n",
    "                      \"precision\": precisions[query_idx],\n",
    "                      \"recall\": recalls[query_idx]}\n",
    "                     for query_idx in range(len(query_ids))]\n",
    "\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5570d4-6f00-4bc1-8ab5-b653dbacd645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'profile_id': ['P14', 'P15', 'P16'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5]]}, {'profile_id': ['P14', 'P15', 'P16'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5]]}, {'profile_id': ['P14', 'P15', 'P16'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5]]}]\n"
     ]
    }
   ],
   "source": [
    "# Extract profiles that are assigned to no cohorts\n",
    "uncohorted_profile_ids = [profile[\"profile_id\"] for profile in tagged_profiles if len(profile[\"cohort_ids\"]) == 0]\n",
    "uncohorted_profile_embeddings = [profile[\"profile_embedding\"] for profile in tagged_profiles if len(profile[\"cohort_ids\"]) == 0]\n",
    "uncohorted_profiles = [{\n",
    "    \"profile_id\": uncohorted_profile_ids,\n",
    "    \"profile_embedding\": uncohorted_profile_embeddings\n",
    "} for query_idx in range(len(query_ids))]\n",
    "\n",
    "print(uncohorted_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0131a48d-3472-4411-bf82-22ff1a4d6e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5'], 'profile_embedding': [[1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1]]}, {'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13'], 'profile_embedding': [[1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1], [-0.5, 0.8660254037844386], [-0.7071067811865475, 0.7071067811865475], [-0.8660254037844386, 0.5], [-1, 0], [-0.8660254037844386, -0.5], [-0.7071067811865475, -0.7071067811865475], [-0.5, -0.8660254037844386], [0, -1]]}, {'profile_id': ['P1', 'P2', 'P3', 'P4', 'P5', 'P9', 'P10', 'P11', 'P12', 'P13'], 'profile_embedding': [[1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1], [-1, 0], [-0.8660254037844386, -0.5], [-0.7071067811865475, -0.7071067811865475], [-0.5, -0.8660254037844386], [0, -1]]}]\n",
      "\n",
      "[11, 19, 16]\n"
     ]
    }
   ],
   "source": [
    "# retrieve the inner profile embeddings for matched cohorts\n",
    "inner_profile_candidates = []\n",
    "cohort_calculation_counts = []\n",
    "for query_idx, cohort_indices in enumerate(all_cohort_indices):\n",
    "    cohort_matched_profile_ids = []\n",
    "    cohort_matched_profile_embeddings = []\n",
    "    # matched_cohort_ids = []\n",
    "    \n",
    "    for cohort_idx in cohort_indices:\n",
    "        cohort_id = cohort_ids[cohort_idx]\n",
    "        # matched_cohort_ids.append(cohort_id)\n",
    "        inner_profile_ids = [profile[\"profile_id\"] for profile in tagged_profiles if cohort_id in profile[\"cohort_ids\"]]\n",
    "        inner_profile_embeddings = [profile[\"profile_embedding\"] for profile in tagged_profiles if profile[\"profile_id\"] in inner_profile_ids]\n",
    "        \n",
    "        cohort_matched_profile_ids.extend(profile_id for profile_id in inner_profile_ids if profile_id not in cohort_matched_profile_ids)\n",
    "        cohort_matched_profile_embeddings.extend(profile_embedding for profile_embedding in inner_profile_embeddings if profile_embedding not in cohort_matched_profile_embeddings)\n",
    "        \n",
    "        profiles_in_cohort = {\n",
    "            \"profile_id\": cohort_matched_profile_ids,\n",
    "            \"profile_embedding\": cohort_matched_profile_embeddings\n",
    "        }\n",
    "   \n",
    "    inner_profile_candidates.append(profiles_in_cohort)\n",
    "    cohort_calculation_counts.append(len(cohort_ids) + len(profiles_in_cohort[\"profile_id\"]) + len(uncohorted_profiles))\n",
    "\n",
    "print(inner_profile_candidates)\n",
    "print()\n",
    "print(cohort_calculation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b735700b-ea6b-402b-af8a-0279b871e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'profile_id': ['P14', 'P15', 'P16', 'P1', 'P2', 'P3', 'P4', 'P5'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5], [1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1]]}, {'profile_id': ['P14', 'P15', 'P16', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5], [1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1], [-0.5, 0.8660254037844386], [-0.7071067811865475, 0.7071067811865475], [-0.8660254037844386, 0.5], [-1, 0], [-0.8660254037844386, -0.5], [-0.7071067811865475, -0.7071067811865475], [-0.5, -0.8660254037844386], [0, -1]]}, {'profile_id': ['P14', 'P15', 'P16', 'P1', 'P2', 'P3', 'P4', 'P5', 'P9', 'P10', 'P11', 'P12', 'P13'], 'profile_embedding': [[0.5, -0.8660254037844386], [0.7071067811865475, -0.7071067811865475], [0.8660254037844386, -0.5], [1, 0], [0.8660254037844386, 0.5], [0.7071067811865475, 0.7071067811865475], [0.5, 0.8660254037844386], [0, 1], [-1, 0], [-0.8660254037844386, -0.5], [-0.7071067811865475, -0.7071067811865475], [-0.5, -0.8660254037844386], [0, -1]]}]\n"
     ]
    }
   ],
   "source": [
    "profiles_to_query = []\n",
    "for query_idx in range(len(query_ids)):\n",
    "    candidate_profiles = {\n",
    "        key: uncohorted_profiles[query_idx][key] + inner_profile_candidates[query_idx][key]\n",
    "        for key in uncohorted_profiles[query_idx]\n",
    "    }\n",
    "    profiles_to_query.append(candidate_profiles)\n",
    "print(profiles_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1143161b-60b9-42de-8139-727da3ff283e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['P14', 'P15', 'P16', 'P1', 'P2', 'P3', 'P4'], ['P5', 'P6', 'P7', 'P8', 'P9', 'P10'], ['P14', 'P15', 'P16', 'P1', 'P12', 'P13']]\n"
     ]
    }
   ],
   "source": [
    "in_range_profile_ids = []\n",
    "for query_idx, profiles in enumerate(profiles_to_query):\n",
    "    embeddings = profiles[\"profile_embedding\"]  # Extract embeddings properly\n",
    "\n",
    "    if len(embeddings) > 0:\n",
    "        profile_knn = NearestNeighbors(algorithm=\"brute\", metric=\"euclidean\", n_jobs=-1)\n",
    "        profile_knn.fit(embeddings)\n",
    "\n",
    "        # Find profiles within query_radius\n",
    "        all_inner_profile_indices = profile_knn.radius_neighbors(\n",
    "            [query_embeddings[query_idx]], radius=query_radius, return_distance=False\n",
    "        )[0]  # Extract first list\n",
    "\n",
    "        # Retrieve profile IDs\n",
    "        matched_profile_ids = [profiles[\"profile_id\"][i] for i in all_inner_profile_indices]\n",
    "        in_range_profile_ids.append(matched_profile_ids)\n",
    "    else:\n",
    "        in_range_profile_ids.append([])\n",
    "\n",
    "print(in_range_profile_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01dabc28-5637-4113-8db5-f982a9758aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "cohort_query_results = np.array([\n",
    "    [\n",
    "        1 if profile[\"profile_id\"] in in_range_profile_ids[q_idx] else 0\n",
    "        for profile in tagged_profiles\n",
    "    ]\n",
    "    for q_idx in range(len(query_ids))\n",
    "])\n",
    "\n",
    "print(cohort_query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba89cd9b-17db-4004-b7a9-bfab08219a26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  8.66025404e-01  7.07106781e-01  5.00000000e-01\n",
      "   0.00000000e+00 -5.00000000e-01 -7.07106781e-01 -8.66025404e-01\n",
      "  -1.00000000e+00 -8.66025404e-01 -7.07106781e-01 -5.00000000e-01\n",
      "   0.00000000e+00  5.00000000e-01  7.07106781e-01  8.66025404e-01]\n",
      " [-8.66025404e-01 -5.00000000e-01 -2.58819045e-01 -1.48741681e-17\n",
      "   5.00000000e-01  8.66025404e-01  9.65925826e-01  1.00000000e+00\n",
      "   8.66025404e-01  5.00000000e-01  2.58819045e-01  1.48741681e-17\n",
      "  -5.00000000e-01 -8.66025404e-01 -9.65925826e-01 -1.00000000e+00]\n",
      " [ 5.00000000e-01  1.48741681e-17 -2.58819045e-01 -5.00000000e-01\n",
      "  -8.66025404e-01 -1.00000000e+00 -9.65925826e-01 -8.66025404e-01\n",
      "  -5.00000000e-01 -1.48741681e-17  2.58819045e-01  5.00000000e-01\n",
      "   8.66025404e-01  1.00000000e+00  9.65925826e-01  8.66025404e-01]]\n",
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def brute_force_search(query_embeddings, profile_embeddings, min_cosine_similarity):\n",
    "    cosine_similarities = cosine_similarity(query_embeddings, profile_embeddings)\n",
    "    print(cosine_similarities)\n",
    "    return [len(profile_embeddings)] * len(query_embeddings), (cosine_similarities >= min_cosine_similarity).astype(int)\n",
    "\n",
    "brute_force_calculation_counts, brute_force_query_results = brute_force_search(query_embeddings, profile_embeddings, 0.5)\n",
    "print(brute_force_query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db07599-72c6-4625-b020-2d9c266dd93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000000000001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.cos(math.pi/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489fb21f-4777-44a4-ae03-4b63aae21455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "def score_results(y_trues: list[list[int]], y_preds: list[list[int]]):\n",
    "    y_trues_counts = [len(y_trues[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    y_preds_counts = [len(y_preds[query_idx]) for query_idx in range(len(y_preds))]\n",
    "    print(f\"Counts of y_trues by query: {y_trues_counts}.\")\n",
    "    print(f\"Counts of y_preds by query: {y_preds_counts}.\")\n",
    "    precisions = [precision_score(y_trues[query_idx], y_preds[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    recalls = [recall_score(y_trues[query_idx], y_preds[query_idx]) for query_idx in range(len(y_trues))]\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f9846c9-1d0d-47b9-bfa4-b7be8dfd4ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of y_trues by query: [16, 16, 16].\n",
      "Counts of y_preds by query: [16, 16, 16].\n"
     ]
    }
   ],
   "source": [
    "precisions, recalls = score_results(brute_force_query_results, cohort_query_results)\n",
    "final_results = [{\"query_id\": query_ids[query_idx],\n",
    "                  \"calculation_count\": cohort_calculation_counts[query_idx],\n",
    "                  \"precision\": precisions[query_idx],\n",
    "                  \"recall\": recalls[query_idx]}\n",
    "                 for query_idx in range(len(queries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1027494-722d-4104-9871-13f331357d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query_id': 'Q1', 'calculation_count': 11, 'precision': 1.0, 'recall': 1.0}, {'query_id': 'Q2', 'calculation_count': 19, 'precision': 1.0, 'recall': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f26a18a-3889-464c-9a5b-2a65746c3ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/cohort/scripts\n"
     ]
    }
   ],
   "source": [
    "# integrating the script into cohorts pipeline\n",
    "import sys\n",
    "import json\n",
    "from load_embeddings import LoadEmbeddings as loader\n",
    "from cohort_utils import get_settings, score_to_length, score_to_similarity, score_to_distance, score_to_cosine_distance, read_objects_from_file, write_objects_to_file, write_objects_to_csv, score_results\n",
    "from cohort_assignment_algorithms_v6 import multiple_cohort_assignment\n",
    "from cohort_querying_algorithms_v6 import brute_force_search, multiple_cohort_querying\n",
    "from cohorts_profiles_distributions import cohorts_and_profiles_distributions\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a4dfb68-e5fc-49d0-984f-1e28e7bb04c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class LoadEmbeddings:\n",
    "    def __init__(self, file_path, embedding_key):\n",
    "        self.file_path = file_path\n",
    "        self.embedding_key = embedding_key\n",
    "\n",
    "    def _read_objects_from_file(self):\n",
    "        \"\"\"Generator to yield JSON objects from a file line-by-line.\"\"\"\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    yield json.loads(line.strip())  # Load each line as a dictionary\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "    def load_cohorts(self):\n",
    "        \"\"\"Load cohort embeddings into a structured dictionary.\"\"\"\n",
    "        cohorts = {\n",
    "            \"cohort_id\": [],\n",
    "            \"cohort_embedding\": []\n",
    "        }\n",
    "\n",
    "        for obj in self._read_objects_from_file():\n",
    "            cohorts[\"cohort_id\"].append(obj.get(\"id\"))\n",
    "            cohorts[\"cohort_embedding\"].append(obj.get(self.embedding_key, []))\n",
    "\n",
    "        cohorts[\"cohort_embedding\"] = normalize(cohorts[\"cohort_embedding\"], axis=1)\n",
    "        \n",
    "        print(f\"Loaded {len(cohorts['cohort_id'])} cohorts.\")\n",
    "        \n",
    "        return cohorts\n",
    "    \n",
    "    def load_profiles(self):\n",
    "        \"\"\"Load profile embeddings into a structured dictionary.\"\"\"\n",
    "        profiles = {\n",
    "            \"profile_id\": [],\n",
    "            \"profile_embedding\": []\n",
    "        }\n",
    "\n",
    "        for obj in self._read_objects_from_file():\n",
    "            profiles[\"profile_id\"].append(obj.get(\"id\"))\n",
    "            profiles[\"profile_embedding\"].append(obj.get(self.embedding_key, []))\n",
    "\n",
    "        profiles[\"profile_embedding\"] = normalize(profiles[\"profile_embedding\"], axis=1)\n",
    "        \n",
    "        print(f\"Loaded {len(profiles['profile_id'])} profiles.\") \n",
    "        \n",
    "        return profiles\n",
    "    \n",
    "    def load_queries(self):\n",
    "        \"\"\"Load query embeddings into a structured dictionary.\"\"\"\n",
    "        queries = {\n",
    "            \"query_id\": [],\n",
    "            \"query_embedding\": []\n",
    "        }\n",
    "\n",
    "        for obj in self._read_objects_from_file():\n",
    "            queries[\"query_id\"].append(obj.get(\"id\"))\n",
    "            queries[\"query_embedding\"].append(obj.get(\"embedding\", []))\n",
    "\n",
    "        queries[\"query_embedding\"] = normalize(queries[\"query_embedding\"], axis=1)\n",
    "        \n",
    "        print(f\"Loaded {len(queries['query_id'])} queries.\") \n",
    "        \n",
    "        return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98c9b99b-52cb-4917-935c-e163c8269fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n",
      "Loaded 1966 cohorts.\n",
      "Loaded 915506 profiles.\n",
      "There are 2 profiles.\n",
      "Loaded 10 queries.\n",
      "There are 2 queries.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/jupyter\")\n",
    "configs = get_settings(\"/home/jupyter/cohort/examples/aipp_cohort_config.example.json\")\n",
    "client = configs[\"client\"]\n",
    "version = configs[\"version\"]\n",
    "embedding_key = configs[\"embedding_key\"]\n",
    "\n",
    "\n",
    "print(\"Loading embeddings...\")\n",
    "cohorts_loader = LoadEmbeddings(configs[\"keyword_embeddings_file_path\"], configs[\"embedding_key\"])\n",
    "cohorts = cohorts_loader.load_cohorts()\n",
    "\n",
    "\n",
    "profiles_loader = LoadEmbeddings(configs[\"profile_embeddings_file_path\"], configs[\"embedding_key\"])\n",
    "profiles = profiles_loader.load_profiles()\n",
    "print(f\"There are {len(profiles)} profiles.\")\n",
    "\n",
    "queries_loader = LoadEmbeddings(configs[\"query_embeddings_file_path\"], configs[\"embedding_key\"])\n",
    "queries = queries_loader.load_queries()\n",
    "print(f\"There are {len(queries)} queries.\")\n",
    "\n",
    "# keywords = read_objects_from_file(configs[\"keyword_embeddings_file_path\"])\n",
    "# cohorts = [loader(keyword, embedding_key).cohorts_dict() for keyword in keywords]\n",
    "# print(f\"Loaded {len(cohorts)} cohorts.\")\n",
    "\n",
    "# profiles_data = read_objects_from_file(configs[\"profile_embeddings_file_path\"])\n",
    "# profiles = [loader(profile, embedding_key).profiles_dict() for profile in profiles_data]\n",
    "# print(f\"Loaded {len(profiles)} profiles.\")\n",
    "\n",
    "# queries_data = read_objects_from_file(configs[\"query_embeddings_file_path\"])\n",
    "# queries = [loader(query, embedding_key).queries_dict() for query in queries_data]\n",
    "# print(f\"Loaded {len(queries)} queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2b8d69-fdc3-4f49-a7c5-cead307477af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', \"'\", 'K', 'Q', 'f']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles[\"profile_id\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5083a2-7c86-4fb7-87c6-33a6b3946deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from cohort_utils import distance_to_length, length_to_distance\n",
    "import tempfile\n",
    "import pickle\n",
    "\n",
    "def brute_force_search(queries, tagged_profiles, min_cosine_similarity):\n",
    "    query_embeddings = np.array(queries[\"query_embedding\"])\n",
    "    profile_embeddings = np.stack([np.array(tagged_profiles[\"profile_embedding\"])])    \n",
    "    cosine_similarities = cosine_similarity(query_embeddings, profile_embeddings)\n",
    "    \n",
    "    similarity_matches = (cosine_similarities > min_cosine_similarity).astype(int)\n",
    "    match_counts = similarity_matches.sum(axis=1)  # Sum over columns (profiles) for each query\n",
    "    print(f\"Profiles matched per query: {match_counts.tolist()}\")  # Convert to list for readable output\n",
    "\n",
    "    return [len(profile_embeddings)] * len(query_embeddings), (cosine_similarities > min_cosine_similarity).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a89ef3df-783e-4c01-9f1e-873680eee699",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m brute_force_calculation_counts, brute_force_query_results \u001b[38;5;241m=\u001b[39m \u001b[43mbrute_force_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mscore_to_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_query_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m, in \u001b[0;36mbrute_force_search\u001b[0;34m(queries, tagged_profiles, min_cosine_similarity)\u001b[0m\n\u001b[1;32m      9\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m profile_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39marray(tagged_profiles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])])    \n\u001b[0;32m---> 11\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m similarity_matches \u001b[38;5;241m=\u001b[39m (cosine_similarities \u001b[38;5;241m>\u001b[39m min_cosine_similarity)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     14\u001b[0m match_counts \u001b[38;5;241m=\u001b[39m similarity_matches\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Sum over columns (profiles) for each query\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:194\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    186\u001b[0m         X,\n\u001b[1;32m    187\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 194\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1058\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "brute_force_calculation_counts, brute_force_query_results = brute_force_search(queries, profiles,\n",
    "                                                                                   score_to_similarity(configs[\"min_query_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0281e-5292-40bb-bf9f-dc6a6b588138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
